{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: no CUDA-capable device is detected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_run\n",
      "low\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "# theano.config.optimizer = 'None' \n",
    "# theano.config.exception_verbosity='high'\n",
    "print theano.config.optimizer\n",
    "print theano.config.exception_verbosity\n",
    "import theano.tensor as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DIMENSIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def setEigenSoFar(self,idx, w, v):\n",
    "#     self.i = idx\n",
    "#     for j in range(self.i):\n",
    "#         self.eigenValues[j] = w[j]\n",
    "#         self.eigenVectors[:,j] = v[:,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array(\n",
    "[[ 0.41939831,  0.73336226,  0.81437075,  0.72610056,  0.76305652,],\n",
    " [ 0.66616774,  0.60886431,  0.92339832,  0.1030873 ,  0.31538147,],\n",
    " [ 0.04194576,  0.29987422,  0.7813136,   0.55106729,  0.58304852,],\n",
    " [ 0.05681328,  0.09614379,  0.83366364,  0.37384903,  0.06315704,],\n",
    " [ 0.97372508,  0.61315203,  0.2581135,   0.44524547,  0.21198589,],]\n",
    ", dtype=np.float32\n",
    ")\n",
    "print X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GradientDescent():\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def __init__(self, dim=5, eta=0.5, numEig=5):\n",
    "        self.DIMENSIONS = dim\n",
    "        self.ETA = eta\n",
    "        self.NUM_EIG = numEig\n",
    "        self.i = 0\n",
    "        self.eigenValues = np.zeros(self.NUM_EIG, dtype=np.float32)\n",
    "        self.eigenVectors = np.zeros((self.DIMENSIONS,self.NUM_EIG), dtype=np.float32)\n",
    "        #         self.i = 0\n",
    "        #         self.eigenValues = theano.shared( np.zeros(self.DIMENSIONS, dtype=np.float32) )\n",
    "        #         self.eigenVectors = theano.shared( np.zeros((self.DIMENSIONS,self.DIMENSIONS), dtype=np.float32) )\n",
    "\n",
    "    def compileTrainer(self):\n",
    "        self.v = theano.shared( np.empty(self.DIMENSIONS, dtype=np.float32), name=\"v\")\n",
    "        self.X = T.fmatrix(name='X')\n",
    "        #     self.X=X\n",
    "\n",
    "        X_dot_v = T.dot(self.X,self.v)\n",
    "        print 'X_dot_v', # theano.pp(X_dot_v)\n",
    "\n",
    "        #         previousEigenContribution = \\\n",
    "        #         np.sum(\n",
    "        #             [self.eigenValues[j]\n",
    "        #              * T.dot(self.eigenVectors[j], self.v)\n",
    "        #              * T.dot(self.eigenVectors[j], self.v)\n",
    "        #                          for j in xrange(self.DIMENSIONS)])\n",
    "        #         eigv_dot_v = T.dot(self.eigenVectors,self.v)\n",
    "        #         previousEigenContribution = T.dot(self.eigenValues,(eigv_dot_v*eigv_dot_v))\n",
    "        previousEigenContribution = np.sum( self.eigenValues[j]\n",
    "                                           *T.dot(self.eigenVectors[j], self.v)\n",
    "                                           *T.dot(self.eigenVectors[j], self.v)\n",
    "                                               for j in xrange(self.NUM_EIG) )\n",
    "        print 'previousEigenContribution', # theano.pp(previousEigenContribution)\n",
    "\n",
    "        # np.sum(gd.eigenVectors[:,j]* gd.v for j in range(gd.i)).eval()\n",
    "\n",
    "        self.objectiveFunction = T.dot(X_dot_v.T, X_dot_v) - previousEigenContribution\n",
    "        print 'self.objectiveFunction', # theano.pp(self.objectiveFunction)\n",
    "\n",
    "        grad_v = T.grad(self.objectiveFunction, self.v)\n",
    "        print 'grad_v', # theano.pp(grad_v)\n",
    "\n",
    "        y = self.v + self.ETA * grad_v\n",
    "        updateFunction = y / y.norm(2)\n",
    "        print 'y', # theano.pp(y)\n",
    "        print 'updateFunction', # theano.pp(updateFunction)\n",
    "\n",
    "        self.train = theano.function(\n",
    "            inputs=[self.X],\n",
    "            outputs=[updateFunction, grad_v, self.objectiveFunction],\n",
    "            updates=((self.v, updateFunction),)\n",
    "        )\n",
    "        print 'self.train trained'#, theano.pp(self.train)\n",
    "\n",
    "    def getNextEigenValueAndVector(self, X_data, epsilon=1e-100, max_iteraions = 20, validateEpsilon=1, initVector = np.array(0).astype('float32')):\n",
    "        if( (initVector.size)<=1 ):\n",
    "            initVector = np.random.rand(self.DIMENSIONS).astype('float32')\n",
    "        self.v.set_value(initVector)\n",
    "        print 'Getting eigen value and vector #', self.i, ' for: X = \\n', X_data\n",
    "        # print 'Starting with a random vector\\n', v.get_value()\n",
    "        last_v_star = self.v.get_value()\n",
    "        checkEpsilon = validateEpsilon\n",
    "        for i in range(max_iteraions):\n",
    "            (update, grad, objective) = self.train(X_data)\n",
    "            #             print update\n",
    "            #             print eigv_dot_v\n",
    "            #             print contrib\n",
    "            # print update, grad, objective, contrib\n",
    "            # self.eigenVectors[:,self.i] = update\n",
    "            rms = sum(update - last_v_star)**2\n",
    "            print 'rms difference: ', rms\n",
    "            last_v_star = update\n",
    "            if(rms < epsilon):\n",
    "                checkEpsilon-=1\n",
    "                if(checkEpsilon<=0):\n",
    "                    break\n",
    "            else:\n",
    "                checkEpsilon=validateEpsilon\n",
    "        self.eigenValues[self.i] = self.objectiveFunction.eval({self.X:X_data})\n",
    "        #         currEigenValues = self.eigenValues.get_value()\n",
    "        #         currEigenValues[self.i] = self.objectiveFunction.eval({self.X:X_data})\n",
    "        #         self.eigenValues.set_value( currEigenValues )\n",
    "\n",
    "        self.eigenVectors[:,self.i] = update\n",
    "        #         currEigenVectors = self.eigenVectors.get_value()\n",
    "        #         currEigenVectors[:,self.i] = last_v_star\n",
    "        #         self.eigenVectors.set_value( currEigenVectors )\n",
    "\n",
    "        #         print \"Eigen Value:\", currEigenValues[self.i]\n",
    "        #         print \"Eigen Vector:\\n\", currEigenVectors[:,self.i]\n",
    "        #         self.i+=1\n",
    "        #         return currEigenValues[self.i-1], currEigenVectors[:,self.i-1]\n",
    "\n",
    "        print \"Eigen Value:\", self.eigenValues[self.i]\n",
    "        print \"Eigen Vector:\\n\", self.eigenVectors[:,self.i]\n",
    "        self.i+=1\n",
    "        return self.eigenValues[self.i-1], self.eigenVectors[:,self.i-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gd1 = GradientDescent( eta=0.5, numEig=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dot_v previousEigenContribution self.objectiveFunction grad_v y updateFunction self.train trained\n"
     ]
    }
   ],
   "source": [
    "gd1.compileTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting eigen value and vector # 0  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "rms difference:  0.330461200354\n",
      "rms difference:  2.28007921246e-05\n",
      "rms difference:  6.51565223997e-05\n",
      "rms difference:  5.27107190695e-06\n",
      "rms difference:  3.25069003715e-07\n",
      "rms difference:  1.920463788e-08\n",
      "rms difference:  1.13612319552e-09\n",
      "rms difference:  6.86419809881e-11\n",
      "rms difference:  4.60431692773e-12\n",
      "rms difference:  1.50102152929e-13\n",
      "rms difference:  7.9936057773e-15\n",
      "rms difference:  8.881784197e-16\n",
      "rms difference:  7.9936057773e-15\n",
      "rms difference:  8.881784197e-16\n",
      "rms difference:  8.881784197e-16\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "rms difference:  0.0\n",
      "Eigen Value: 6.69674\n",
      "Eigen Vector:\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.6967435,\n",
       " array([ 0.38626757,  0.43620911,  0.61527091,  0.38440156,  0.36632782], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd1.getNextEigenValueAndVector(X_data, max_iteraions=100, epsilon=1e-50, validateEpsilon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 6.69674349  0.          0.        ]\n",
      "[[ 0.38626757  0.          0.        ]\n",
      " [ 0.43620911  0.          0.        ]\n",
      " [ 0.61527091  0.          0.        ]\n",
      " [ 0.38440156  0.          0.        ]\n",
      " [ 0.36632782  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print gd1.i\n",
    "print gd1.eigenValues\n",
    "print gd1.eigenVectors\n",
    "# print gd1.eigenValues.get_value()\n",
    "# print gd1.eigenVectors.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dot_v previousEigenContribution self.objectiveFunction grad_v y updateFunction self.train trained\n",
      "Getting eigen value and vector # 1  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: A.shape[1] != x.shape[0]\nApply node that caused the error: CGemv{inplace}(AllocEmpty{dtype='float32'}.0, TensorConstant{1.0}, InplaceDimShuffle{x,0}.0, TensorConstant{[ 0.386267...        ]}, TensorConstant{0.0})\nToposort index: 6\nInputs types: [TensorType(float32, (True,)), TensorType(float32, scalar), TensorType(float32, row), TensorType(float32, vector), TensorType(float32, scalar)]\nInputs shapes: [(1,), (), (1, 5), (3,), ()]\nInputs strides: [(4,), (), (20, 4), (4,), ()]\nInputs values: [array([ 0.21198589], dtype=float32), array(1.0, dtype=float32), array([[ 0.21139863,  0.79400939,  0.42193195,  0.31013119,  0.26615757]], dtype=float32), array([ 0.38626757,  0.        ,  0.        ], dtype=float32), array(0.0, dtype=float32)]\nOutputs clients: [[Elemwise{mul,no_inplace}(TensorConstant{(1,) of -6.69674}, CGemv{inplace}.0, TensorConstant{[ 0.386267...        ]}), InplaceDimShuffle{}(CGemv{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3af541211d64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompileTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNextEigenValueAndVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iteraions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidateEpsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-8b3fad9a321f>\u001b[0m in \u001b[0;36mgetNextEigenValueAndVector\u001b[1;34m(self, X_data, epsilon, max_iteraions, validateEpsilon, initVector)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mcheckEpsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidateEpsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iteraions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;31m#             print update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m#             print eigv_dot_v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    880\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: A.shape[1] != x.shape[0]\nApply node that caused the error: CGemv{inplace}(AllocEmpty{dtype='float32'}.0, TensorConstant{1.0}, InplaceDimShuffle{x,0}.0, TensorConstant{[ 0.386267...        ]}, TensorConstant{0.0})\nToposort index: 6\nInputs types: [TensorType(float32, (True,)), TensorType(float32, scalar), TensorType(float32, row), TensorType(float32, vector), TensorType(float32, scalar)]\nInputs shapes: [(1,), (), (1, 5), (3,), ()]\nInputs strides: [(4,), (), (20, 4), (4,), ()]\nInputs values: [array([ 0.21198589], dtype=float32), array(1.0, dtype=float32), array([[ 0.21139863,  0.79400939,  0.42193195,  0.31013119,  0.26615757]], dtype=float32), array([ 0.38626757,  0.        ,  0.        ], dtype=float32), array(0.0, dtype=float32)]\nOutputs clients: [[Elemwise{mul,no_inplace}(TensorConstant{(1,) of -6.69674}, CGemv{inplace}.0, TensorConstant{[ 0.386267...        ]}), InplaceDimShuffle{}(CGemv{inplace}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "gd1.compileTrainer()\n",
    "gd1.getNextEigenValueAndVector(X_data, max_iteraions=100, epsilon=1e-50, validateEpsilon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gd1.i\n",
    "print gd1.eigenValues\n",
    "print gd1.eigenVectors\n",
    "# print gd1.eigenValues.get_value()\n",
    "# print gd1.eigenVectors.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w_np,v_np = np.linalg.eigh( np.dot(X_data.T,X_data) )\n",
    "print X_data\n",
    "w_np,v_np = np.linalg.eigh(np.dot(X_data.T,X_data))\n",
    "idx = np.argsort(-w_np)\n",
    "w_np = w_np[idx]\n",
    "v_np = v_np[:,idx]\n",
    "# for i in range(DIMENSIONS):\n",
    "#     print w_np[i]\n",
    "#     print v_np[:,i]\n",
    "print w_np.astype('float32')\n",
    "print v_np.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gd=gd1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp = gd.eigenVectors.eval()\n",
    "# temp[:,1] = 0\n",
    "# temp\n",
    "# gd.eigenVectors.set_value(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print gd.v.eval()\n",
    "# print gd.eigenVectors.eval()\n",
    "# print np.sum(gd.eigenVectors[:,j]* gd.v for j in range(gd.i)).eval()\n",
    "# print gd.i\n",
    "# print\n",
    "# print (gd.eigenVectors*gd.v).eval()\n",
    "# print ((gd.eigenVectors*gd.v)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (T.sum(gd.eigenVectors*gd.v)).eval()\n",
    "# print (T.sum(gd.eigenVectors*gd.v, axis=0)).eval()\n",
    "# print (T.sum(gd.eigenVectors*gd.v, axis=1)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print T.dot(gd.eigenVectors[1], gd.v).eval()\n",
    "# print gd.v.eval()\n",
    "# print gd.eigenVectors[1].eval()\n",
    "# print (T.dot(gd.eigenVectors[1], gd.v)**2).eval()\n",
    "# print (gd.eigenValues[1]*(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print ((T.dot(gd.eigenVectors[1], gd.v))).eval()\n",
    "# print (T.dot(gd.eigenVectors,gd.v)).eval()\n",
    "# print ((T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print (T.dot(gd.eigenVectors,gd.v)**2).eval()\n",
    "# print (gd.eigenValues[1]*(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print (gd.eigenValues*(T.dot(gd.eigenVectors,gd.v)**2)).eval()\n",
    "# print T.dot(gd.eigenValues,(T.dot(gd.eigenVectors,gd.v)**2)).eval()\n",
    "# print (gd.eigenValues(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# # T.sum?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
