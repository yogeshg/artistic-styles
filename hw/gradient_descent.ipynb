{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_run\n",
      "low\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "# theano.config.optimizer = 'None' \n",
    "# theano.config.exception_verbosity='high'\n",
    "print theano.config.optimizer\n",
    "print theano.config.exception_verbosity\n",
    "import theano.tensor as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DIMENSIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def setEigenSoFar(self,idx, w, v):\n",
    "#     self.i = idx\n",
    "#     for j in range(self.i):\n",
    "#         self.eigenValues[j] = w[j]\n",
    "#         self.eigenVectors[:,j] = v[:,j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n"
     ]
    }
   ],
   "source": [
    "X_data = np.array(\n",
    "[[ 0.41939831,  0.73336226,  0.81437075,  0.72610056,  0.76305652,],\n",
    " [ 0.66616774,  0.60886431,  0.92339832,  0.1030873 ,  0.31538147,],\n",
    " [ 0.04194576,  0.29987422,  0.7813136,   0.55106729,  0.58304852,],\n",
    " [ 0.05681328,  0.09614379,  0.83366364,  0.37384903,  0.06315704,],\n",
    " [ 0.97372508,  0.61315203,  0.2581135,   0.44524547,  0.21198589,],]\n",
    ", dtype=np.float32\n",
    ")\n",
    "print X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GradientDescent():\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def __init__(self, dim=5, eta=0.5, numEig=5):\n",
    "        self.DIMENSIONS = dim\n",
    "        self.ETA = eta\n",
    "        self.NUM_EIG = numEig\n",
    "        self.i = 0\n",
    "        self.eigenValues = np.zeros(self.NUM_EIG, dtype=np.float32)\n",
    "        self.eigenVectors = np.zeros((self.DIMENSIONS,self.NUM_EIG), dtype=np.float32)\n",
    "        #         self.i = 0\n",
    "        #         self.eigenValues = theano.shared( np.zeros(self.DIMENSIONS, dtype=np.float32) )\n",
    "        #         self.eigenVectors = theano.shared( np.zeros((self.DIMENSIONS,self.DIMENSIONS), dtype=np.float32) )\n",
    "\n",
    "    def compileTrainer(self):\n",
    "        self.v = theano.shared( np.empty(self.DIMENSIONS, dtype=np.float32), name=\"v\")\n",
    "        self.X = T.fmatrix(name='X')\n",
    "        #     self.X=X\n",
    "\n",
    "        X_dot_v = T.dot(self.X,self.v)\n",
    "        print 'X_dot_v', # theano.pp(X_dot_v)\n",
    "\n",
    "        #         previousEigenContribution = \\\n",
    "        #         np.sum(\n",
    "        #             [self.eigenValues[j]\n",
    "        #              * T.dot(self.eigenVectors[j], self.v)\n",
    "        #              * T.dot(self.eigenVectors[j], self.v)\n",
    "        #                          for j in xrange(self.DIMENSIONS)])\n",
    "        #         eigv_dot_v = T.dot(self.eigenVectors,self.v)\n",
    "        #         previousEigenContribution = T.dot(self.eigenValues,(eigv_dot_v*eigv_dot_v))\n",
    "        previousEigenContribution = np.sum( self.eigenValues[j]\n",
    "                                           *T.dot(self.eigenVectors[:,j], self.v)\n",
    "                                           *T.dot(self.eigenVectors[:,j], self.v)\n",
    "                                               for j in xrange(self.NUM_EIG) )\n",
    "        print 'previousEigenContribution', # theano.pp(previousEigenContribution)\n",
    "\n",
    "        # np.sum(gd.eigenVectors[:,j]* gd.v for j in range(gd.i)).eval()\n",
    "\n",
    "        self.objectiveFunction = T.dot(X_dot_v.T, X_dot_v) - previousEigenContribution\n",
    "        print 'self.objectiveFunction', # theano.pp(self.objectiveFunction)\n",
    "\n",
    "        grad_v = T.grad(self.objectiveFunction, self.v)\n",
    "        print 'grad_v', # theano.pp(grad_v)\n",
    "\n",
    "        y = self.v + self.ETA * grad_v\n",
    "        updateFunction = y / y.norm(2)\n",
    "        print 'y', # theano.pp(y)\n",
    "        print 'updateFunction', # theano.pp(updateFunction)\n",
    "\n",
    "        self.train = theano.function(\n",
    "            inputs=[self.X],\n",
    "            outputs=[updateFunction, grad_v, self.objectiveFunction, previousEigenContribution],\n",
    "            updates=((self.v, updateFunction),)\n",
    "        )\n",
    "        print 'self.train trained'#, theano.pp(self.train)\n",
    "        \n",
    "    def getNextEigenValueAndVector(self, X_data, epsilon=1e-100, max_iteraions = 20, validateEpsilon=1):\n",
    "        initVector = np.random.rand(self.DIMENSIONS).astype('float32')\n",
    "        self.v.set_value(initVector)\n",
    "        print 'Getting eigen value and vector #', self.i #, ' for: X = \\n', X_data\n",
    "        # print 'Starting with a random vector\\n', v.get_value()\n",
    "        last_v_star = self.v.get_value()\n",
    "        checkEpsilon = validateEpsilon\n",
    "        for i in range(max_iteraions):\n",
    "            (update, grad, objective, contrib) = self.train(X_data)\n",
    "            # print update\n",
    "            #             print eigv_dot_v\n",
    "            # print contrib\n",
    "            # print update, grad, objective, contrib\n",
    "            # self.eigenVectors[:,self.i] = update\n",
    "            rms = sum(update - last_v_star)**2\n",
    "            # print 'rms difference: ', rms\n",
    "            last_v_star = update\n",
    "            if(rms < epsilon):\n",
    "                checkEpsilon-=1\n",
    "                if(checkEpsilon<=0):\n",
    "                    break\n",
    "            else:\n",
    "                checkEpsilon=validateEpsilon\n",
    "        print 'Number of iterations done: ', i\n",
    "        self.eigenValues[self.i] = self.objectiveFunction.eval({self.X:X_data})\n",
    "        #         currEigenValues = self.eigenValues.get_value()\n",
    "        #         currEigenValues[self.i] = self.objectiveFunction.eval({self.X:X_data})\n",
    "        #         self.eigenValues.set_value( currEigenValues )\n",
    "\n",
    "        self.eigenVectors[:,self.i] = update\n",
    "        #         currEigenVectors = self.eigenVectors.get_value()\n",
    "        #         currEigenVectors[:,self.i] = last_v_star\n",
    "        #         self.eigenVectors.set_value( currEigenVectors )\n",
    "\n",
    "        #         print \"Eigen Value:\", currEigenValues[self.i]\n",
    "        #         print \"Eigen Vector:\\n\", currEigenVectors[:,self.i]\n",
    "        #         self.i+=1\n",
    "        #         return currEigenValues[self.i-1], currEigenVectors[:,self.i-1]\n",
    "\n",
    "        print \"Eigen Value:\", self.eigenValues[self.i]\n",
    "        print \"Eigen Vector:\\n\", self.eigenVectors[:,self.i]\n",
    "        self.i+=1\n",
    "        return self.eigenValues[self.i-1], self.eigenVectors[:,self.i-1]\n",
    "\n",
    "    def getAllEigenValuesAndVectors(self, X_data, epsilon=1e-100, max_iteraions = 20, validateEpsilon=1):\n",
    "        for e in range(self.NUM_EIG):\n",
    "            self.compileTrainer()\n",
    "            self.getNextEigenValueAndVector(X_data, epsilon=epsilon, max_iteraions=max_iteraions, validateEpsilon=validateEpsilon)\n",
    "        return self.eigenValues, self.eigenVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gd1 = GradientDescent( eta=0.5, numEig=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dot_v previousEigenContribution (((TensorConstant{0} + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v)))\n",
      "self.objectiveFunction grad_v y updateFunction self.train trained\n",
      "Getting eigen value and vector # 0  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "Eigen Value: 6.69674\n",
      "Eigen Vector:\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "X_dot_v previousEigenContribution (((TensorConstant{0} + ((TensorConstant{6.69674348831} * (TensorConstant{[ 0.386267...36632782]} \\dot v)) * (TensorConstant{[ 0.386267...36632782]} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v)))\n",
      "self.objectiveFunction grad_v y updateFunction self.train trained\n",
      "Getting eigen value and vector # 1  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "Eigen Value: 0.917017\n",
      "Eigen Vector:\n",
      "[ 0.77879918  0.3049418  -0.48440343 -0.17088737 -0.19139816]\n",
      "X_dot_v previousEigenContribution (((TensorConstant{0} + ((TensorConstant{6.69674348831} * (TensorConstant{[ 0.386267...36632782]} \\dot v)) * (TensorConstant{[ 0.386267...36632782]} \\dot v))) + ((TensorConstant{0.917016506195} * (TensorConstant{[ 0.778799...19139816]} \\dot v)) * (TensorConstant{[ 0.778799...19139816]} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v)))\n",
      "self.objectiveFunction grad_v y updateFunction self.train trained\n",
      "Getting eigen value and vector # 2  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "Eigen Value: 0.357899\n",
      "Eigen Vector:\n",
      "[-0.18951496  0.12934482 -0.62004143  0.53058237  0.53045732]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 6.69674349,  0.91701651,  0.35789928], dtype=float32),\n",
       " array([[ 0.38626757,  0.77879918, -0.18951496],\n",
       "        [ 0.43620911,  0.3049418 ,  0.12934482],\n",
       "        [ 0.61527091, -0.48440343, -0.62004143],\n",
       "        [ 0.38440156, -0.17088737,  0.53058237],\n",
       "        [ 0.36632782, -0.19139816,  0.53045732]], dtype=float32))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd1.getAllEigenValuesAndVectors(X_data, epsilon=1e-30, max_iteraions=50, validateEpsilon=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "[  6.69674349e+00   9.17016327e-01   3.57899129e-01   1.17424600e-01\n",
      "   5.43444697e-03]\n",
      "[[-0.3862676  -0.77879918 -0.18949656 -0.17551515 -0.42137238]\n",
      " [-0.43620914 -0.30494162  0.12930381  0.3579978   0.75620782]\n",
      " [-0.61527091  0.48440337 -0.62004066 -0.01953718 -0.04430548]\n",
      " [-0.38440156  0.1708875   0.53066385 -0.72879076  0.10145342]\n",
      " [-0.36632782  0.19139819  0.5303933   0.5563401  -0.48820004]]\n"
     ]
    }
   ],
   "source": [
    "# w_np,v_np = np.linalg.eigh( np.dot(X_data.T,X_data) )\n",
    "print X_data\n",
    "w_np,v_np = np.linalg.eigh(np.dot(X_data.T,X_data))\n",
    "idx = np.argsort(-w_np)\n",
    "w_np = w_np[idx]\n",
    "v_np = v_np[:,idx]\n",
    "# for i in range(DIMENSIONS):\n",
    "#     print w_np[i]\n",
    "#     print v_np[:,i]\n",
    "print w_np.astype('float32')\n",
    "print v_np.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "## Test single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dot_v previousEigenContribution (((TensorConstant{0} + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v)))\n",
      "self.objectiveFunction grad_v y updateFunction self.train trained\n"
     ]
    }
   ],
   "source": [
    "gd1.compileTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting eigen value and vector # 0  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "[ 0.45982906  0.44589075  0.51229298  0.39309907  0.41565335]\n",
      "0.0\n",
      "rms difference:  0.930760143038\n",
      "[ 0.40474829  0.44200686  0.59409225  0.38568959  0.3729701 ]\n",
      "0.0\n",
      "rms difference:  0.000743005538127\n",
      "[ 0.39086437  0.4379791   0.61067843  0.38441151  0.36701357]\n",
      "0.0\n",
      "rms difference:  7.32751623298e-05\n",
      "[ 0.38741863  0.43668219  0.61424249  0.38433728  0.3663421 ]\n",
      "0.0\n",
      "rms difference:  3.70295417529e-06\n",
      "[ 0.38655666  0.43632978  0.615035    0.38437244  0.36630604]\n",
      "0.0\n",
      "rms difference:  1.78739330892e-07\n",
      "[ 0.38634017  0.43623936  0.61521572  0.38439184  0.36631823]\n",
      "0.0\n",
      "rms difference:  8.9477545373e-09\n",
      "[ 0.38628578  0.43621662  0.6152578   0.38439864  0.36632472]\n",
      "0.0\n",
      "rms difference:  4.73310279858e-10\n",
      "[ 0.38627216  0.43621102  0.61526775  0.38440078  0.36632696]\n",
      "0.0\n",
      "rms difference:  2.38884467763e-11\n",
      "[ 0.38626876  0.43620962  0.61527014  0.38440138  0.36632761]\n",
      "0.0\n",
      "rms difference:  1.35091937636e-12\n",
      "[ 0.3862679   0.43620929  0.61527073  0.3844015   0.36632776]\n",
      "0.0\n",
      "rms difference:  1.07469588784e-13\n",
      "[ 0.38626763  0.43620917  0.61527085  0.38440153  0.36632782]\n",
      "0.0\n",
      "rms difference:  3.19744231092e-14\n",
      "[ 0.38626763  0.43620914  0.61527091  0.38440159  0.36632785]\n",
      "0.0\n",
      "rms difference:  1.42108547152e-14\n",
      "[ 0.3862676   0.43620911  0.61527097  0.38440153  0.36632782]\n",
      "0.0\n",
      "rms difference:  7.9936057773e-15\n",
      "[ 0.3862676   0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  8.881784197e-16\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  8.881784197e-16\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n",
      "0.0\n",
      "rms difference:  0.0\n",
      "Eigen Value: 6.69674\n",
      "Eigen Vector:\n",
      "[ 0.38626757  0.43620911  0.61527091  0.38440156  0.36632782]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.6967435,\n",
       " array([ 0.38626757,  0.43620911,  0.61527091,  0.38440156,  0.36632782], dtype=float32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd1.getNextEigenValueAndVector(X_data, max_iteraions=100, epsilon=1e-50, validateEpsilon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 6.69674349  0.          0.        ]\n",
      "[[ 0.38626757  0.          0.        ]\n",
      " [ 0.43620911  0.          0.        ]\n",
      " [ 0.61527091  0.          0.        ]\n",
      " [ 0.38440156  0.          0.        ]\n",
      " [ 0.36632782  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print gd1.i\n",
    "print gd1.eigenValues\n",
    "print gd1.eigenVectors\n",
    "# print gd1.eigenValues.get_value()\n",
    "# print gd1.eigenVectors.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dot_v previousEigenContribution (((TensorConstant{0} + ((TensorConstant{6.69674348831} * (TensorConstant{[ 0.386267...36632782]} \\dot v)) * (TensorConstant{[ 0.386267...36632782]} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v))) + ((TensorConstant{0.0} * (TensorConstant{(5,) of 0.0} \\dot v)) * (TensorConstant{(5,) of 0.0} \\dot v)))\n",
      "self.objectiveFunction grad_v y updateFunction self.train trained\n",
      "Getting eigen value and vector # 1  for: X = \n",
      "[[ 0.41939831  0.73336226  0.81437075  0.72610056  0.76305652]\n",
      " [ 0.66616774  0.60886431  0.92339832  0.1030873   0.31538147]\n",
      " [ 0.04194576  0.29987422  0.7813136   0.55106729  0.58304852]\n",
      " [ 0.05681328  0.09614379  0.83366364  0.37384903  0.06315704]\n",
      " [ 0.97372508  0.61315203  0.2581135   0.44524547  0.21198589]]\n",
      "[ 0.08179311  0.46953464 -0.08456524  0.74217641  0.4635407 ]\n",
      "4.90696430206\n",
      "rms difference:  0.213686477769\n",
      "[ 0.0471461   0.41959554 -0.21662676  0.73355669  0.48650211]\n",
      "2.73853349686\n",
      "rms difference:  0.0409276974962\n",
      "[ 0.02355248  0.37125468 -0.33539158  0.70850444  0.49714115]\n",
      "1.86806118488\n",
      "rms difference:  0.0420711422886\n",
      "[ 0.01581907  0.33109909 -0.43663329  0.67289811  0.49667171]\n",
      "1.17654240131\n",
      "rms difference:  0.0343014389742\n",
      "[ 0.0272679   0.30290821 -0.52183425  0.63119787  0.48660177]\n",
      "0.696498095989\n",
      "rms difference:  0.0236277467832\n",
      "[ 0.06072737  0.28791636 -0.59471071  0.5845474   0.4669475 ]\n",
      "0.393757730722\n",
      "rms difference:  0.0145717657948\n",
      "[ 0.11884119  0.28560141 -0.65785617  0.53081149  0.43562937]\n",
      "0.214324295521\n",
      "rms difference:  0.00853787831847\n",
      "[ 0.20260477  0.29382947 -0.71017975  0.46575862  0.38901046]\n",
      "0.112053953111\n",
      "rms difference:  0.00518453386346\n",
      "[ 0.30784211  0.30838758 -0.74582905  0.38575625  0.32413182]\n",
      "0.0554819144309\n",
      "rms difference:  0.003688724197\n",
      "[ 0.42206848  0.32324475 -0.75701666  0.2921505   0.24278569]\n",
      "0.0253846216947\n",
      "rms difference:  0.00325538144921\n",
      "[ 0.52755946  0.33301067 -0.74127293  0.19384205  0.1540283 ]\n",
      "0.0104515692219\n",
      "rms difference:  0.00314330684832\n",
      "[ 0.61108738  0.33590847 -0.70580471  0.1031372   0.07028576]\n",
      "0.00382390012965\n",
      "rms difference:  0.00276186537507\n",
      "[  6.69866323e-01   3.33666980e-01  -6.62677467e-01   2.83554364e-02\n",
      "   2.26379678e-04]\n",
      "0.00125731294975\n",
      "rms difference:  0.00204091198593\n",
      "[ 0.70841575  0.32900789 -0.62143552 -0.02869919 -0.05380608]\n",
      "0.000382019527024\n",
      "rms difference:  0.00129274787519\n",
      "[ 0.73295587  0.32390633 -0.58665258 -0.07031842 -0.0935647 ]\n",
      "0.000110408938781\n",
      "rms difference:  0.000737466698766\n",
      "[ 0.74852794  0.31933713 -0.55929899 -0.0999988  -0.12212565]\n",
      "3.10089017148e-05\n",
      "rms difference:  0.000395408329601\n",
      "[ 0.75851673  0.31561673 -0.53863275 -0.12095603 -0.14241795]\n",
      "8.57702343637e-06\n",
      "rms difference:  0.000204916499691\n",
      "[ 0.76502985  0.31274086 -0.52338284 -0.13570271 -0.15677236]\n",
      "2.35415700445e-06\n",
      "rms difference:  0.000104324445409\n",
      "[ 0.76934975  0.31058481 -0.51228929 -0.14607407 -0.16691314]\n",
      "6.43371549813e-07\n",
      "rms difference:  5.26309584217e-05\n",
      "[ 0.77225912  0.30899844 -0.50429106 -0.15337352 -0.17407723]\n",
      "1.75938978941e-07\n",
      "rms difference:  2.64435693822e-05\n",
      "[ 0.77424359  0.30784532 -0.49855727 -0.15851632 -0.17914058]\n",
      "4.7948070403e-08\n",
      "rms difference:  1.32568404363e-05\n",
      "[ 0.7756108   0.30701375 -0.49446231 -0.16214353 -0.18272118]\n",
      "1.31164643591e-08\n",
      "rms difference:  6.64203938872e-06\n",
      "[ 0.77655989  0.30641723 -0.49154508 -0.16470419 -0.18525444]\n",
      "3.58630170005e-09\n",
      "rms difference:  3.32743437803e-06\n",
      "[ 0.77722257  0.30599099 -0.4894703  -0.16651317 -0.18704732]\n",
      "9.75604819153e-10\n",
      "rms difference:  1.66573683047e-06\n",
      "[ 0.77768713  0.30568704 -0.48799664 -0.16779205 -0.1883167 ]\n",
      "2.85267365285e-10\n",
      "rms difference:  8.35382334197e-07\n",
      "[ 0.77801389  0.30547085 -0.4869507  -0.16869648 -0.18921553]\n",
      "7.96903792954e-11\n",
      "rms difference:  4.18272883884e-07\n",
      "[ 0.77824414  0.30531716 -0.48620871 -0.16933635 -0.18985207]\n",
      "2.63031142006e-11\n",
      "rms difference:  2.09643087112e-07\n",
      "[ 0.77840656  0.30520797 -0.48568273 -0.16978921 -0.19030298]\n",
      "1.04921002442e-11\n",
      "rms difference:  1.05340616452e-07\n",
      "[ 0.7785213   0.30513045 -0.4853099  -0.17010982 -0.19062239]\n",
      "3.86762366925e-12\n",
      "rms difference:  5.2886026447e-08\n",
      "[ 0.77860248  0.30507553 -0.48504561 -0.17033674 -0.1908486 ]\n",
      "9.29359887658e-13\n",
      "rms difference:  2.64343926748e-08\n",
      "[ 0.77865994  0.30503657 -0.48485833 -0.17049742 -0.19100887]\n",
      "5.65422546023e-13\n",
      "rms difference:  1.32609443426e-08\n",
      "[ 0.77870059  0.30500895 -0.48472574 -0.17061125 -0.19112243]\n",
      "4.81780143124e-13\n",
      "rms difference:  6.68757138556e-09\n",
      "[ 0.77872926  0.30498934 -0.48463178 -0.17069186 -0.19120286]\n",
      "1.48697582567e-13\n",
      "rms difference:  3.36691474701e-09\n",
      "[ 0.7787497   0.30497551 -0.48456511 -0.17074887 -0.1912598 ]\n",
      "3.71743940537e-16\n",
      "rms difference:  1.65366409455e-09\n",
      "[ 0.77876413  0.30496567 -0.48451796 -0.17078927 -0.19130014]\n",
      "7.28618147804e-14\n",
      "rms difference:  8.40864267104e-10\n",
      "[ 0.77877438  0.30495873 -0.48448449 -0.17081788 -0.19132872]\n",
      "7.28618147804e-14\n",
      "rms difference:  4.16755518984e-10\n",
      "[ 0.77878159  0.30495378 -0.48446086 -0.17083816 -0.19134898]\n",
      "1.63939066315e-13\n",
      "rms difference:  2.14559259248e-10\n",
      "[ 0.77878672  0.30495024 -0.48444414 -0.17085256 -0.19136332]\n",
      "1.07433999847e-13\n",
      "rms difference:  1.08801856413e-10\n",
      "[ 0.77879035  0.30494776 -0.48443225 -0.17086267 -0.19137347]\n",
      "5.94790304859e-15\n",
      "rms difference:  5.20152809713e-11\n",
      "[ 0.77879298  0.30494609 -0.48442376 -0.17086986 -0.19138065]\n",
      "3.01112589452e-14\n",
      "rms difference:  2.41806574763e-11\n",
      "[ 0.77879477  0.3049449  -0.48441777 -0.17087494 -0.1913857 ]\n",
      "2.14124508055e-13\n",
      "rms difference:  1.25774946014e-11\n",
      "[ 0.77879608  0.30494404 -0.4844135  -0.17087854 -0.19138932]\n",
      "3.80665795109e-13\n",
      "rms difference:  6.34181596126e-12\n",
      "[ 0.77879709  0.30494347 -0.48441046 -0.17088106 -0.19139184]\n",
      "4.2973599939e-13\n",
      "rms difference:  2.40163444687e-12\n",
      "[ 0.77879763  0.30494291 -0.48440844 -0.17088294 -0.19139372]\n",
      "1.25054664974e-12\n",
      "rms difference:  3.09174907898e-12\n",
      "[ 0.7787981   0.30494261 -0.48440695 -0.17088422 -0.19139501]\n",
      "3.12636662435e-13\n",
      "rms difference:  8.26227974926e-13\n",
      "[ 0.77879846  0.30494237 -0.48440591 -0.17088516 -0.19139595]\n",
      "3.34569530283e-13\n",
      "rms difference:  5.11590769747e-13\n",
      "[ 0.77879864  0.30494219 -0.48440513 -0.1708858  -0.19139659]\n",
      "1.96652549388e-13\n",
      "rms difference:  2.56683563293e-13\n",
      "[ 0.77879876  0.30494204 -0.48440471 -0.17088631 -0.19139709]\n",
      "2.91447259122e-13\n",
      "rms difference:  3.73256980879e-13\n",
      "[ 0.77879888  0.30494198 -0.48440427 -0.17088661 -0.19139737]\n",
      "5.94790304859e-15\n",
      "rms difference:  5.55111512313e-15\n",
      "[ 0.77879894  0.30494189 -0.48440403 -0.17088686 -0.19139762]\n",
      "1.20445035781e-13\n",
      "rms difference:  8.881784197e-14\n",
      "[ 0.77879906  0.30494189 -0.48440382 -0.17088699 -0.19139776]\n",
      "9.29359891046e-15\n",
      "rms difference:  3.5527136788e-15\n",
      "[ 0.77879912  0.30494189 -0.48440361 -0.17088708 -0.19139785]\n",
      "8.36423825709e-14\n",
      "rms difference:  7.9936057773e-15\n",
      "[ 0.77879918  0.30494192 -0.48440349 -0.17088714 -0.19139791]\n",
      "2.51298900309e-13\n",
      "rms difference:  7.9936057773e-15\n",
      "[ 0.77879912  0.30494183 -0.48440352 -0.17088723 -0.19139802]\n",
      "5.9479033027e-13\n",
      "rms difference:  1.50102152929e-13\n",
      "[ 0.77879924  0.30494189 -0.48440334 -0.17088722 -0.19139799]\n",
      "7.28618147804e-14\n",
      "rms difference:  1.6187051699e-13\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088729 -0.19139805]\n",
      "6.87354524426e-13\n",
      "rms difference:  6.41708908233e-14\n",
      "[ 0.77879918  0.30494183 -0.48440337 -0.17088734 -0.1913981 ]\n",
      "2.91447259122e-13\n",
      "rms difference:  1.42108547152e-14\n",
      "[ 0.77879918  0.30494186 -0.48440337 -0.17088737 -0.19139813]\n",
      "1.79924068808e-13\n",
      "rms difference:  8.881784197e-16\n",
      "[ 0.77879912  0.30494183 -0.48440337 -0.17088735 -0.19139811]\n",
      "1.63939066315e-13\n",
      "rms difference:  3.5527136788e-15\n",
      "[ 0.77879918  0.30494186 -0.48440331 -0.17088734 -0.1913981 ]\n",
      "1.07433999847e-13\n",
      "rms difference:  3.19744231092e-14\n",
      "[ 0.77879912  0.30494174 -0.48440346 -0.17088743 -0.19139819]\n",
      "4.2973599939e-13\n",
      "rms difference:  2.56683563293e-13\n",
      "[ 0.77879912  0.30494171 -0.48440349 -0.17088743 -0.19139819]\n",
      "1.48697576215e-15\n",
      "rms difference:  3.5527136788e-15\n",
      "[ 0.77879912  0.30494171 -0.48440343 -0.17088743 -0.19139817]\n",
      "1.33827817534e-14\n",
      "rms difference:  5.55111512313e-15\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "1.48697576215e-15\n",
      "rms difference:  2.68673971959e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "[ 0.77879918  0.3049418  -0.48440331 -0.17088737 -0.19139813]\n",
      "2.37916121943e-14\n",
      "rms difference:  4.35207425653e-14\n",
      "[ 0.77879918  0.3049418  -0.4844034  -0.17088737 -0.19139814]\n",
      "1.63939066315e-13\n",
      "rms difference:  1.08801856413e-14\n",
      "[ 0.77879918  0.30494183 -0.48440334 -0.17088735 -0.19139811]\n",
      "5.35311270138e-14\n",
      "rms difference:  1.79856129989e-14\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n",
      "2.32339971915e-13\n",
      "rms difference:  5.68434188608e-14\n",
      "Eigen Value: 0.917016\n",
      "Eigen Vector:\n",
      "[ 0.77879912  0.30494177 -0.4844034  -0.17088738 -0.19139814]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.91701639,\n",
       " array([ 0.77879912,  0.30494177, -0.4844034 , -0.17088738, -0.19139814], dtype=float32))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd1.compileTrainer()\n",
    "gd1.getNextEigenValueAndVector(X_data, max_iteraions=100, epsilon=1e-50, validateEpsilon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[ 6.69674349  0.91701639  0.        ]\n",
      "[[ 0.38626757  0.77879912  0.        ]\n",
      " [ 0.43620911  0.30494177  0.        ]\n",
      " [ 0.61527091 -0.4844034   0.        ]\n",
      " [ 0.38440156 -0.17088738  0.        ]\n",
      " [ 0.36632782 -0.19139814  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print gd1.i\n",
    "print gd1.eigenValues\n",
    "print gd1.eigenVectors\n",
    "# print gd1.eigenValues.get_value()\n",
    "# print gd1.eigenVectors.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gd=gd1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temp = gd.eigenVectors.eval()\n",
    "# temp[:,1] = 0\n",
    "# temp\n",
    "# gd.eigenVectors.set_value(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print gd.v.eval()\n",
    "# print gd.eigenVectors.eval()\n",
    "# print np.sum(gd.eigenVectors[:,j]* gd.v for j in range(gd.i)).eval()\n",
    "# print gd.i\n",
    "# print\n",
    "# print (gd.eigenVectors*gd.v).eval()\n",
    "# print ((gd.eigenVectors*gd.v)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (T.sum(gd.eigenVectors*gd.v)).eval()\n",
    "# print (T.sum(gd.eigenVectors*gd.v, axis=0)).eval()\n",
    "# print (T.sum(gd.eigenVectors*gd.v, axis=1)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print T.dot(gd.eigenVectors[1], gd.v).eval()\n",
    "# print gd.v.eval()\n",
    "# print gd.eigenVectors[1].eval()\n",
    "# print (T.dot(gd.eigenVectors[1], gd.v)**2).eval()\n",
    "# print (gd.eigenValues[1]*(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print ((T.dot(gd.eigenVectors[1], gd.v))).eval()\n",
    "# print (T.dot(gd.eigenVectors,gd.v)).eval()\n",
    "# print ((T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print (T.dot(gd.eigenVectors,gd.v)**2).eval()\n",
    "# print (gd.eigenValues[1]*(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# print (gd.eigenValues*(T.dot(gd.eigenVectors,gd.v)**2)).eval()\n",
    "# print T.dot(gd.eigenValues,(T.dot(gd.eigenVectors,gd.v)**2)).eval()\n",
    "# print (gd.eigenValues(T.dot(gd.eigenVectors[1], gd.v)**2)).eval()\n",
    "# # T.sum?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.0dev2.dev-26445969216722c8bc23548b6a39f26033caba39'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
