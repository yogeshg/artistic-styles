<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=wMXA-lZiHBMEZ-dBsKceyg');.lst-kix_1gm9o9wcd7pg-0>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-0,decimal) ". "}.lst-kix_f0cuw8wlviqi-7>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-7}.lst-kix_6nqn63a3krj0-7>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-7}ol.lst-kix_6wajunywya39-6{list-style-type:none}.lst-kix_1gm9o9wcd7pg-1>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-1,lower-latin) ". "}.lst-kix_1gm9o9wcd7pg-2>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-2,lower-roman) ". "}ol.lst-kix_6wajunywya39-7{list-style-type:none}ol.lst-kix_6nqn63a3krj0-8.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-8 0}ol.lst-kix_6wajunywya39-4{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-0.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-0 0}ol.lst-kix_6wajunywya39-5{list-style-type:none}ol.lst-kix_6wajunywya39-2{list-style-type:none}.lst-kix_6wajunywya39-7>li{counter-increment:lst-ctn-kix_6wajunywya39-7}ol.lst-kix_6wajunywya39-3{list-style-type:none}.lst-kix_ex0q9wj3jmqv-0>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-0}ol.lst-kix_6wajunywya39-0{list-style-type:none}ol.lst-kix_6wajunywya39-1{list-style-type:none}ol.lst-kix_k49x0wlmrunk-6.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-6 0}ol.lst-kix_1gm9o9wcd7pg-2.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-2 0}ol.lst-kix_6wajunywya39-8{list-style-type:none}.lst-kix_k49x0wlmrunk-3>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-3}ol.lst-kix_ex0q9wj3jmqv-0.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-0 0}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}.lst-kix_1gm9o9wcd7pg-3>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-3}ol.lst-kix_1gm9o9wcd7pg-7.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-7 0}ol.lst-kix_6nqn63a3krj0-2.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-2 0}ol.lst-kix_6wajunywya39-5.start{counter-reset:lst-ctn-kix_6wajunywya39-5 0}.lst-kix_f0cuw8wlviqi-7>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-7,lower-latin) ". "}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_f0cuw8wlviqi-6>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-6,decimal) ". "}.lst-kix_f0cuw8wlviqi-8>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-8,lower-roman) ". "}.lst-kix_ex0q9wj3jmqv-2>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-2}.lst-kix_6nqn63a3krj0-5>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-5}.lst-kix_f0cuw8wlviqi-0>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-0,decimal) ". "}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}.lst-kix_f0cuw8wlviqi-3>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-3,decimal) ". "}ol.lst-kix_1gm9o9wcd7pg-1.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-1 0}.lst-kix_f0cuw8wlviqi-4>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-4,lower-latin) ". "}.lst-kix_f0cuw8wlviqi-5>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-5,lower-roman) ". "}ol.lst-kix_f0cuw8wlviqi-5.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-5 0}ol.lst-kix_6wajunywya39-0.start{counter-reset:lst-ctn-kix_6wajunywya39-0 0}ol.lst-kix_ex0q9wj3jmqv-5.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-5 0}.lst-kix_f0cuw8wlviqi-2>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-2,lower-roman) ". "}ol.lst-kix_k49x0wlmrunk-0.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-0 0}.lst-kix_6wajunywya39-3>li{counter-increment:lst-ctn-kix_6wajunywya39-3}.lst-kix_f0cuw8wlviqi-1>li:before{content:"" counter(lst-ctn-kix_f0cuw8wlviqi-1,lower-latin) ". "}.lst-kix_f0cuw8wlviqi-5>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-5}.lst-kix_ex0q9wj3jmqv-4>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-4}.lst-kix_6nqn63a3krj0-8>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-8,lower-roman) ". "}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}.lst-kix_6nqn63a3krj0-6>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-6,decimal) ". "}.lst-kix_list_3-0>li{counter-increment:lst-ctn-kix_list_3-0}ol.lst-kix_list_4-0.start{counter-reset:lst-ctn-kix_list_4-0 0}ol.lst-kix_6nqn63a3krj0-7.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-7 0}.lst-kix_6nqn63a3krj0-7>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-7,lower-latin) ". "}.lst-kix_1gm9o9wcd7pg-5>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-5,lower-roman) ". "}.lst-kix_1gm9o9wcd7pg-6>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-6,decimal) ". "}ol.lst-kix_1gm9o9wcd7pg-8.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-8 0}ol.lst-kix_k49x0wlmrunk-1.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-1 0}.lst-kix_1gm9o9wcd7pg-3>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-3,decimal) ". "}.lst-kix_1gm9o9wcd7pg-4>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-4,lower-latin) ". "}.lst-kix_1gm9o9wcd7pg-7>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-7,lower-latin) ". "}.lst-kix_1gm9o9wcd7pg-8>li:before{content:"" counter(lst-ctn-kix_1gm9o9wcd7pg-8,lower-roman) ". "}ol.lst-kix_f0cuw8wlviqi-6.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-6 0}ol.lst-kix_k49x0wlmrunk-7.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-7 0}.lst-kix_1gm9o9wcd7pg-7>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-7}ol.lst-kix_ex0q9wj3jmqv-6.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-6 0}.lst-kix_1gm9o9wcd7pg-1>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-1}.lst-kix_k49x0wlmrunk-5>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-5}ol.lst-kix_list_1-3{list-style-type:none}.lst-kix_ex0q9wj3jmqv-7>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-7,lower-latin) ". "}ol.lst-kix_list_1-4{list-style-type:none}.lst-kix_list_2-7>li:before{content:" "}.lst-kix_v16i7znt6euc-2>li:before{content:"-  "}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-5>li:before{content:" "}.lst-kix_ex0q9wj3jmqv-6>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-6}.lst-kix_v16i7znt6euc-0>li:before{content:"-  "}ol.lst-kix_list_1-1{list-style-type:none}.lst-kix_v16i7znt6euc-4>li:before{content:"-  "}.lst-kix_k49x0wlmrunk-4>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-4,lower-latin) ". "}.lst-kix_k49x0wlmrunk-8>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-8,lower-roman) ". "}ol.lst-kix_list_1-2{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-6.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-6 0}.lst-kix_ex0q9wj3jmqv-5>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-5,lower-roman) ". "}.lst-kix_6nqn63a3krj0-1>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-1}.lst-kix_k49x0wlmrunk-6>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-6,decimal) ". "}ol.lst-kix_6wajunywya39-6.start{counter-reset:lst-ctn-kix_6wajunywya39-6 0}.lst-kix_f0cuw8wlviqi-2>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-2}.lst-kix_6nqn63a3krj0-0>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-0,decimal) ". "}ul.lst-kix_list_3-7{list-style-type:none}ul.lst-kix_list_3-8{list-style-type:none}.lst-kix_ex0q9wj3jmqv-1>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-1,lower-latin) ". "}.lst-kix_6nqn63a3krj0-2>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-2,lower-roman) ". "}.lst-kix_v16i7znt6euc-8>li:before{content:"-  "}ol.lst-kix_list_3-0.start{counter-reset:lst-ctn-kix_list_3-0 0}ul.lst-kix_list_3-1{list-style-type:none}ul.lst-kix_list_3-2{list-style-type:none}.lst-kix_6nqn63a3krj0-4>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-4,lower-latin) ". "}.lst-kix_ex0q9wj3jmqv-3>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-3,decimal) ". "}ol.lst-kix_f0cuw8wlviqi-7.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-7 0}ol.lst-kix_list_1-7{list-style-type:none}ul.lst-kix_list_3-5{list-style-type:none}ol.lst-kix_list_1-8{list-style-type:none}ul.lst-kix_list_3-6{list-style-type:none}.lst-kix_6nqn63a3krj0-0>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-0}ul.lst-kix_list_3-3{list-style-type:none}.lst-kix_v16i7znt6euc-6>li:before{content:"-  "}ul.lst-kix_list_3-4{list-style-type:none}ol.lst-kix_6wajunywya39-3.start{counter-reset:lst-ctn-kix_6wajunywya39-3 0}.lst-kix_1gm9o9wcd7pg-6>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-6}.lst-kix_ex0q9wj3jmqv-7>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-7}.lst-kix_list_4-1>li:before{content:" "}.lst-kix_ex0q9wj3jmqv-5>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-5}.lst-kix_list_4-3>li:before{content:" "}.lst-kix_list_4-5>li:before{content:" "}ol.lst-kix_1gm9o9wcd7pg-3.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-3 0}ol.lst-kix_ex0q9wj3jmqv-4.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-4 0}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}.lst-kix_6wajunywya39-1>li{counter-increment:lst-ctn-kix_6wajunywya39-1}ol.lst-kix_ex0q9wj3jmqv-1.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-1 0}ol.lst-kix_6wajunywya39-4.start{counter-reset:lst-ctn-kix_6wajunywya39-4 0}ol.lst-kix_ex0q9wj3jmqv-2.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-2 0}.lst-kix_1gm9o9wcd7pg-5>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-5}ol.lst-kix_6nqn63a3krj0-3.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-3 0}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ul.lst-kix_list_2-8{list-style-type:none}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}ul.lst-kix_list_2-2{list-style-type:none}ul.lst-kix_list_2-3{list-style-type:none}ul.lst-kix_list_2-1{list-style-type:none}ul.lst-kix_list_2-6{list-style-type:none}.lst-kix_list_1-1>li:before{content:" "}ul.lst-kix_list_2-7{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-4.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-4 0}ul.lst-kix_list_2-4{list-style-type:none}ul.lst-kix_list_2-5{list-style-type:none}.lst-kix_list_1-3>li:before{content:" "}.lst-kix_6wajunywya39-8>li{counter-increment:lst-ctn-kix_6wajunywya39-8}ol.lst-kix_1gm9o9wcd7pg-5.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-5 0}.lst-kix_list_1-7>li:before{content:" "}ol.lst-kix_ex0q9wj3jmqv-3.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-3 0}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}.lst-kix_list_1-5>li:before{content:" "}.lst-kix_6wajunywya39-2>li{counter-increment:lst-ctn-kix_6wajunywya39-2}.lst-kix_6wajunywya39-2>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-2,lower-roman) ". "}ol.lst-kix_6nqn63a3krj0-4.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-4 0}.lst-kix_list_2-1>li:before{content:" "}.lst-kix_f0cuw8wlviqi-3>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-3}.lst-kix_list_2-3>li:before{content:" "}.lst-kix_6wajunywya39-4>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-4,lower-latin) ". "}.lst-kix_k49x0wlmrunk-4>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-4}.lst-kix_6wajunywya39-8>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-8,lower-roman) ". "}.lst-kix_6wajunywya39-6>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-6,decimal) ". "}.lst-kix_6wajunywya39-7>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-7,lower-latin) ". "}ol.lst-kix_list_3-0{list-style-type:none}ol.lst-kix_6wajunywya39-2.start{counter-reset:lst-ctn-kix_6wajunywya39-2 0}.lst-kix_1gm9o9wcd7pg-2>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-2}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}.lst-kix_list_3-0>li:before{content:"" counter(lst-ctn-kix_list_3-0,decimal) ". "}.lst-kix_6nqn63a3krj0-6>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-6}.lst-kix_list_3-1>li:before{content:" "}.lst-kix_list_3-2>li:before{content:" "}.lst-kix_6wajunywya39-0>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-0,decimal) ". "}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}.lst-kix_list_4-0>li{counter-increment:lst-ctn-kix_list_4-0}.lst-kix_list_3-5>li:before{content:" "}.lst-kix_ex0q9wj3jmqv-1>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-1}ol.lst-kix_k49x0wlmrunk-3.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-3 0}.lst-kix_list_3-4>li:before{content:" "}.lst-kix_f0cuw8wlviqi-8>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-8}.lst-kix_list_3-3>li:before{content:" "}.lst-kix_6wajunywya39-6>li{counter-increment:lst-ctn-kix_6wajunywya39-6}ol.lst-kix_6nqn63a3krj0-5.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-5 0}ol.lst-kix_f0cuw8wlviqi-8.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-8 0}ol.lst-kix_ex0q9wj3jmqv-8.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-8 0}.lst-kix_1gm9o9wcd7pg-0>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-0}.lst-kix_list_3-8>li:before{content:" "}ol.lst-kix_6nqn63a3krj0-0.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-0 0}.lst-kix_list_2-0>li{counter-increment:lst-ctn-kix_list_2-0}.lst-kix_list_3-6>li:before{content:" "}.lst-kix_list_3-7>li:before{content:" "}.lst-kix_k49x0wlmrunk-6>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-6}.lst-kix_6wajunywya39-4>li{counter-increment:lst-ctn-kix_6wajunywya39-4}.lst-kix_6nqn63a3krj0-8>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-8}ol.lst-kix_list_2-0{list-style-type:none}ol.lst-kix_6nqn63a3krj0-6.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-6 0}.lst-kix_list_4-8>li:before{content:" "}ol.lst-kix_k49x0wlmrunk-7{list-style-type:none}ol.lst-kix_k49x0wlmrunk-8{list-style-type:none}.lst-kix_list_4-7>li:before{content:" "}.lst-kix_6nqn63a3krj0-4>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-4}.lst-kix_f0cuw8wlviqi-4>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-4}ul.lst-kix_list_4-8{list-style-type:none}.lst-kix_ex0q9wj3jmqv-8>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-8}ol.lst-kix_k49x0wlmrunk-0{list-style-type:none}ul.lst-kix_list_4-6{list-style-type:none}ol.lst-kix_k49x0wlmrunk-1{list-style-type:none}ul.lst-kix_list_4-7{list-style-type:none}ol.lst-kix_k49x0wlmrunk-2{list-style-type:none}ol.lst-kix_k49x0wlmrunk-3{list-style-type:none}ol.lst-kix_k49x0wlmrunk-4{list-style-type:none}ol.lst-kix_k49x0wlmrunk-5{list-style-type:none}ol.lst-kix_k49x0wlmrunk-6{list-style-type:none}ul.lst-kix_list_4-1{list-style-type:none}ol.lst-kix_6wajunywya39-8.start{counter-reset:lst-ctn-kix_6wajunywya39-8 0}ul.lst-kix_list_4-4{list-style-type:none}ul.lst-kix_list_4-5{list-style-type:none}ol.lst-kix_k49x0wlmrunk-8.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-8 0}ul.lst-kix_list_4-2{list-style-type:none}ul.lst-kix_list_4-3{list-style-type:none}ol.lst-kix_6wajunywya39-1.start{counter-reset:lst-ctn-kix_6wajunywya39-1 0}.lst-kix_k49x0wlmrunk-0>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-0,decimal) ". "}.lst-kix_k49x0wlmrunk-1>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-1,lower-latin) ". "}.lst-kix_k49x0wlmrunk-8>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-8}.lst-kix_1gm9o9wcd7pg-4>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-4}ol.lst-kix_6wajunywya39-7.start{counter-reset:lst-ctn-kix_6wajunywya39-7 0}.lst-kix_k49x0wlmrunk-2>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-2}ol.lst-kix_6nqn63a3krj0-1.start{counter-reset:lst-ctn-kix_6nqn63a3krj0-1 0}.lst-kix_k49x0wlmrunk-3>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-3,decimal) ". "}.lst-kix_k49x0wlmrunk-2>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-2,lower-roman) ". "}ul.lst-kix_v16i7znt6euc-6{list-style-type:none}.lst-kix_k49x0wlmrunk-5>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-5,lower-roman) ". "}.lst-kix_list_2-6>li:before{content:" "}.lst-kix_v16i7znt6euc-1>li:before{content:"-  "}ul.lst-kix_v16i7znt6euc-5{list-style-type:none}ul.lst-kix_v16i7znt6euc-8{list-style-type:none}ol.lst-kix_ex0q9wj3jmqv-8{list-style-type:none}ul.lst-kix_v16i7znt6euc-7{list-style-type:none}ol.lst-kix_ex0q9wj3jmqv-7{list-style-type:none}ol.lst-kix_ex0q9wj3jmqv-7.start{counter-reset:lst-ctn-kix_ex0q9wj3jmqv-7 0}.lst-kix_list_2-4>li:before{content:" "}.lst-kix_list_2-8>li:before{content:" "}ol.lst-kix_ex0q9wj3jmqv-6{list-style-type:none}ol.lst-kix_ex0q9wj3jmqv-5{list-style-type:none}.lst-kix_ex0q9wj3jmqv-8>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-8,lower-roman) ". "}.lst-kix_ex0q9wj3jmqv-4>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-4,lower-latin) ". "}ol.lst-kix_ex0q9wj3jmqv-4{list-style-type:none}ul.lst-kix_v16i7znt6euc-0{list-style-type:none}ul.lst-kix_v16i7znt6euc-2{list-style-type:none}ol.lst-kix_k49x0wlmrunk-2.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-2 0}.lst-kix_k49x0wlmrunk-7>li:before{content:"" counter(lst-ctn-kix_k49x0wlmrunk-7,lower-latin) ". "}.lst-kix_f0cuw8wlviqi-1>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-1}ul.lst-kix_v16i7znt6euc-1{list-style-type:none}.lst-kix_v16i7znt6euc-3>li:before{content:"-  "}.lst-kix_ex0q9wj3jmqv-6>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-6,decimal) ". "}ul.lst-kix_v16i7znt6euc-4{list-style-type:none}ul.lst-kix_v16i7znt6euc-3{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-1{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-0{list-style-type:none}.lst-kix_6nqn63a3krj0-1>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-1,lower-latin) ". "}ol.lst-kix_f0cuw8wlviqi-4.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-4 0}.lst-kix_ex0q9wj3jmqv-0>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-0,decimal) ". "}.lst-kix_6wajunywya39-0>li{counter-increment:lst-ctn-kix_6wajunywya39-0}.lst-kix_v16i7znt6euc-5>li:before{content:"-  "}ol.lst-kix_f0cuw8wlviqi-8{list-style-type:none}.lst-kix_6nqn63a3krj0-5>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-5,lower-roman) ". "}ol.lst-kix_f0cuw8wlviqi-7{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-6{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-5{list-style-type:none}.lst-kix_v16i7znt6euc-7>li:before{content:"-  "}ol.lst-kix_f0cuw8wlviqi-4{list-style-type:none}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}.lst-kix_6nqn63a3krj0-3>li:before{content:"" counter(lst-ctn-kix_6nqn63a3krj0-3,decimal) ". "}ol.lst-kix_f0cuw8wlviqi-3{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-2{list-style-type:none}.lst-kix_ex0q9wj3jmqv-2>li:before{content:"" counter(lst-ctn-kix_ex0q9wj3jmqv-2,lower-roman) ". "}ol.lst-kix_k49x0wlmrunk-5.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-5 0}.lst-kix_list_4-0>li:before{content:"" counter(lst-ctn-kix_list_4-0,decimal) ". "}ol.lst-kix_f0cuw8wlviqi-1.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-1 0}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_list_4-4>li:before{content:" "}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}.lst-kix_1gm9o9wcd7pg-8>li{counter-increment:lst-ctn-kix_1gm9o9wcd7pg-8}.lst-kix_list_4-2>li:before{content:" "}.lst-kix_list_4-6>li:before{content:" "}ol.lst-kix_ex0q9wj3jmqv-3{list-style-type:none}.lst-kix_6nqn63a3krj0-2>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-2}ol.lst-kix_ex0q9wj3jmqv-2{list-style-type:none}ol.lst-kix_ex0q9wj3jmqv-1{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-0.start{counter-reset:lst-ctn-kix_1gm9o9wcd7pg-0 0}ol.lst-kix_ex0q9wj3jmqv-0{list-style-type:none}ol.lst-kix_list_4-0{list-style-type:none}ol.lst-kix_f0cuw8wlviqi-2.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-2 0}.lst-kix_ex0q9wj3jmqv-3>li{counter-increment:lst-ctn-kix_ex0q9wj3jmqv-3}.lst-kix_k49x0wlmrunk-7>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-7}ol.lst-kix_6nqn63a3krj0-0{list-style-type:none}ol.lst-kix_6nqn63a3krj0-1{list-style-type:none}ol.lst-kix_6nqn63a3krj0-2{list-style-type:none}ol.lst-kix_6nqn63a3krj0-3{list-style-type:none}ol.lst-kix_6nqn63a3krj0-4{list-style-type:none}ol.lst-kix_6nqn63a3krj0-5{list-style-type:none}.lst-kix_k49x0wlmrunk-1>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-1}ol.lst-kix_6nqn63a3krj0-6{list-style-type:none}ol.lst-kix_6nqn63a3krj0-7{list-style-type:none}ol.lst-kix_6nqn63a3krj0-8{list-style-type:none}.lst-kix_6nqn63a3krj0-3>li{counter-increment:lst-ctn-kix_6nqn63a3krj0-3}ol.lst-kix_1gm9o9wcd7pg-0{list-style-type:none}.lst-kix_list_1-0>li:before{content:" "}.lst-kix_k49x0wlmrunk-0>li{counter-increment:lst-ctn-kix_k49x0wlmrunk-0}ol.lst-kix_1gm9o9wcd7pg-3{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-4{list-style-type:none}.lst-kix_list_1-2>li:before{content:" "}ol.lst-kix_list_2-0.start{counter-reset:lst-ctn-kix_list_2-0 0}ol.lst-kix_1gm9o9wcd7pg-1{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-2{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-7{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-8{list-style-type:none}.lst-kix_list_1-4>li:before{content:" "}ol.lst-kix_1gm9o9wcd7pg-5{list-style-type:none}ol.lst-kix_1gm9o9wcd7pg-6{list-style-type:none}.lst-kix_6wajunywya39-5>li{counter-increment:lst-ctn-kix_6wajunywya39-5}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}.lst-kix_f0cuw8wlviqi-6>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-6}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_1-6>li:before{content:" "}.lst-kix_6wajunywya39-1>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-1,lower-latin) ". "}.lst-kix_6wajunywya39-3>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-3,decimal) ". "}.lst-kix_list_2-0>li:before{content:"" counter(lst-ctn-kix_list_2-0,decimal) ". "}ol.lst-kix_f0cuw8wlviqi-3.start{counter-reset:lst-ctn-kix_f0cuw8wlviqi-3 0}.lst-kix_list_1-8>li:before{content:" "}.lst-kix_list_2-2>li:before{content:" "}.lst-kix_6wajunywya39-5>li:before{content:"" counter(lst-ctn-kix_6wajunywya39-5,lower-roman) ". "}.lst-kix_f0cuw8wlviqi-0>li{counter-increment:lst-ctn-kix_f0cuw8wlviqi-0}ol.lst-kix_k49x0wlmrunk-4.start{counter-reset:lst-ctn-kix_k49x0wlmrunk-4 0}ol{margin:0;padding:0}table td,table th{padding:0}.c24{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:45.8pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:65.2pt;border-top-color:#000000;border-bottom-style:solid}.c17{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:316.2pt;border-top-color:#000000;border-bottom-style:solid}.c15{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:63.8pt;border-top-color:#000000;border-bottom-style:solid}.c3{vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-weight:400}.c29{border-spacing:0;border-collapse:collapse;margin-right:auto}.c1{orphans:2;text-indent:12.2pt;widows:2;text-align:justify}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c19{color:#000000;text-decoration:none;font-style:normal}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.0}.c4{orphans:2;widows:2;text-align:justify}.c0{orphans:2;widows:2;text-align:center}.c33{background-color:#ffffff;max-width:491pt;padding:72pt 60.5pt 72pt 60.5pt}.c25{color:inherit;text-decoration:inherit}.c34{padding:0;margin:0}.c13{orphans:2;widows:2}.c27{color:#1155cc;text-decoration:underline}.c5{vertical-align:baseline;font-size:10pt}.c16{font-family:"Times New Roman";font-weight:400}.c7{font-size:10pt;text-decoration:underline}.c20{margin-left:36pt;padding-left:0pt}.c12{font-size:8pt;font-family:"Courier New"}.c18{font-family:"Times New Roman"}.c31{font-style:normal}.c14{font-style:italic}.c2{font-weight:700}.c8{font-size:10pt}.c22{color:#ff0000}.c11{vertical-align:baseline}.c30{font-size:14pt}.c28{text-indent:13.5pt}.c23{height:0pt}.c9{color:#0000ff}.c32{text-align:left}.c10{height:12pt}.c35{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:0pt;font-family:"Federo";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:center}.subtitle{padding-top:12pt;color:#666666;font-size:14pt;padding-bottom:6pt;font-family:"Arial";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:center}li{color:#000000;font-size:12pt;font-family:"Times New Roman"}p{margin:0;color:#000000;font-size:12pt;font-family:"Times New Roman"}h1{padding-top:3pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:0pt;font-family:"Federo";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:2pt;color:#000000;font-size:11pt;padding-bottom:0pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c33"><div><p class="c13 c10"><span class="c22"></span></p></div><p class="c0"><span class="c2 c30">A Neural Algorithm of Artistic Style</span></p><p class="c0"><span>E4040.2016Fall.NAAH.report</span></p><p class="c0"><span>&nbsp;Francis Marcogliese fam2148, Richard Godden rg3047, Yogesh Garg yg2482</span></p><p class="c0"><span class="c14">Columbia University</span></p><p class="c0 c10"><span class="c5 c16"></span></p><p class="c13 c10"><span class="c3"></span></p><p class="c0"><span class="c2 c11">Abstract</span></p><p class="c4"><span class="c8 c14">Several neural algorithms have been implemented to extract style information from one image and content information from another to generate a new image with both elements. This report aims to recreate one of these networks to produce eye catching results, as it is a novel use of CNNs to separate elements such as content and style from images. Implementing the loss function for this project with the hardware limitations required specific effort to process the the CNN&rsquo;s outputs at various layers which was solved with tools in the Theano library. Several pictures combining style form paintings and photo content were generated with visually appealing results.</span></p><p class="c4 c10"><span class="c5 c16"></span></p><p class="c13"><span class="c2 c11">1. Introduction</span></p><p class="c4 c28"><span class="c8">Deep neural networks are a type of convolutional neural network especially adept at feature extraction from image content [2]. Being biologically inspired, some networks even approach human accuracy for some tasks, such a facial recognition [3]. One such network, VGG, was the best classification network in the ImageNet challenge 2014 [4]. VGG-19, one of the networks used by the VGG team, is therefore a useful tool for feature extraction from many types of images. By examining the outputs of the VGG-19 network at various layers, different aspects of the input can be discovered - for example, certain layers carry information that is more tightly associated with style, and others more tightly associated with content [5].</span></p><p class="c4 c28"><span class="c8">As shown by Gatys et al. [5], the information could be used within a custom loss function with a white noise image, to create a combination of the content with the style of another image. As there is no strict definition for what the human brain distinguishes as content or as style in an image, the main challenges associated with this task are defining which convolutional layers should be chosen for the &ldquo;style&rdquo; and which for the &ldquo;content&rdquo;. Similarly, when combining these data in the loss function, it is also difficult to choose the how to weight each layer, as the quality of the result is highly dependant on the choice of inputs. From an implementation perspective, it was challenging to correctly define the gradient of a more complex loss function, linking the whole computational graph together through different classes. This was solved through careful use of the built-in Theano functions and logic. Additionally, training VGG-19 proved non trivial due to memory constraints on AWS.</span></p><p class="c4 c28 c10"><span class="c8"></span></p><p class="c4"><span class="c2">2. Summary of the Original Paper</span></p><p class="c4"><span class="c2">2.1 Methodology of the Original Paper</span></p><p class="c4"><span class="c2">&nbsp; &nbsp; &nbsp;</span><span class="c8">The following section describes how the data in the original paper was processed to transfer style from one image to the content of another.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 312.00px; height: 236.00px;"><img alt="VGG(1).png" src="images/image04.png" style="width: 312.00px; height: 236.21px; margin-left: 0.00px; margin-top: -0.11px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c13"><span class="c8">Figure 1: Graph depicting the structure of network to combine style and content into a new image. Inspired from [7]</span></p><p class="c10 c13"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 1 summarizes succinctly how the original paper [5] processes the input images to produce a new result. The authors identify 5 principal layers that contain the style information and 1 layer that provides the content information. The style image and the new image, which can start off as white noise, fed forward through VGG and 5 activations are kept. The Gram matrix of each activation is calculated for each layer, and the weighted mean squared error is taken between the matrices for style and the new image, to give a style loss. Similarly, the squared difference between Gram matrices for the content layers is taken as the content loss. The weighted sum of the 2 gives the total loss, which is minimized to give a visually interesting generated image. The authors also used average pooling instead of max pooling. They claim that this offered visually superior results to max pooling when doing the reconstructions. The Caffe framework was used to obtain the results described in the original paper and the VGG-19 network was initialized with the weights from the developers of VGG-19 as opposed to retraining the network over ImageNet.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c2">2.2 Key Results of the Original Paper</span></p><p class="c4"><span class="c2">&nbsp; &nbsp;</span><span class="c8">The first key result of this paper is that style and content can be extracted separately on different layers of a deep convolutional neural network. Higher levels in the convolutional network (deeper into the network) give high level content [5], such as broad brush features or big swirls such as in the </span><span class="c14 c8">Starry Night</span><span class="c8">&nbsp;painting, whereas the more detailed brush strokes is found in lower levels. This is why a higher level (conv4_2) is used to extract content information. This is shown in Figure 2, taken from the original paper [5].</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 312.00px; height: 216.00px;"><img alt="keyresultpaper.png" src="images/image19.png" style="width: 312.00px; height: 216.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 2: This shows how content and style can be found in the outputs of different layers of the network. Deeper layers show more content. From [5]</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">&nbsp; &nbsp;For style representations, the authors described a method to get correlations between between different style elements in the input image, for example proximity between certain brush stroke or lines or colours [5][6]. This is done by taking the Gram matrix of the activation at a certain layer.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;This has a certain consistency with biological systems, as complex cells would perform the same correlations between stylistic features that are distinguished from the content - which possible what is done by humans&rsquo; primary visual cortex. </span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;Additionally, colours are most heavily sourced in the style image, as well as the local structures and these features are organized in a way that is consistent with the content of the content input image. </span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c2">3</span><span class="c2 c11">. Methodology</span></p><p class="c4"><span class="c2">&nbsp; &nbsp; </span><span class="c8">This section presents the methodology used to design the architecture for the code presented in this paper [1]. The differences between this code and the code in the original paper are also presented.</span></p><p class="c1"><span class="c8">In an effort to recreate the results present by the original paper by Gatys </span><span class="c14 c8">et al., </span><span class="c8">a very similar methodology was used. The same gradient structure and loss function were used as described in Figure 1. However, an important difference is that the Theano library was used as a project requirement, as opposed to the Caffe framework in the original project. VGG-19 was created from scratch for the computational graph to style transfer activation functions.</span></p><p class="c1"><span class="c8">In addition, this version gave the option of using 3 different optimizers, gradient descent, Adam and L-BFGS to compare the varying results. The original paper uses solely L-BFGS.</span></p><p class="c1"><span class="c8">The original paper used normalized weights in the VGG-19 so that the mean activations at the desired layers would equal to 1. This paper does not do this, due to coding complexity and time limitations.</span></p><p class="c1"><span class="c8">Finally, the authors slightly modified VGG-19 by changing the type of pooling the 5 pooling layers form max pooling to average pooling. This significantly slowed down computation and despite the author&#39;s claiming that it improved results, it was excluded for efficiency reasons.</span></p><p class="c4 c10"><span class="c5 c16"></span></p><p class="c4"><span class="c2">3</span><span class="c2 c11">.1. Objectives and Technical Challenges</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; The principal objective of this project is to recreate the style transfer network shown in the original paper and produce visually appealing images with style from one input and content from another.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp;One of the greatest challenges in this project was handling the numerous memory errors thrown when doing style transfers on high resolution images (more than 1000x1000 pixels). The AWS instances used (g2.2large and g2.8large) were largely insufficient in terms of memory as they threw errors if more than 4GB of RAM was used at any given time. This was solved by creating a minimum number of VGG-19 classes to minimize memory used by those objects.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; Processing power was also a limitation, as training high resolution images could take several hours when using average pooling. This limited some of the methodology choices to have acceptable training times for each iterations.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp;Another important challenge was finding the correct parameters to obtain visually pleasing images, as this was the metric of success for a style transfer, as no concrete metric of style and content currently exists. There are 3 very important parameters that direct image reconstructions, </span><span class="c14 c8">alpha, </span><span class="c8">which gives the weight of the content loss in the total loss, </span><span class="c14 c8">beta, </span><span class="c8">which gives the weight of the style loss in the total loss and </span><span class="c14 c8">w_l</span><span class="c8">&nbsp;which represents the individual weighting of each style activation in the style loss. The parameters balance how much the generated image matches the content or the style, and fine-tuning them for general cases has proved to be a trial-and-error process, limiting the number of combinations that could be tested efficiently. </span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;Finally, when recreating a personal version of VGG-19, a number of attempts were made to train it to have personal weights to attempt image reconstructions with those. However, training VGG-19 requires a dataset that is not freely accessible by the general public and requires a lot of training to get to similar results to the weights provided by the creators of the network. Therefore, those weights were used.</span></p><p class="c4 c10"><span class="c5 c16"></span></p><p class="c4"><span class="c2">3</span><span class="c2 c11">.2. Problem Formulation and Design </span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp;As the main objective is producing images with style form one input and content from another, the problem is how to extract the relevant data from the inputs and how to use these data to obtain a new, generated image.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; The tool used to extract the interesting features from images is a deep convolutional neural network, VGG-19. The numerous convolutions and pooling steps extract different features at different layers of the network.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp;These features are combined according to the following loss function:</span></p><p class="c0"><img src="images/image00.png"></p><p class="c0"><img src="images/image01.png"></p><p class="c0"><img src="images/image02.png"></p><p class="c0"><img src="images/image03.png"></p><p class="c13 c32"><span class="c8">where G is the Gram matrix of the activation of that particular layer. </span></p><p class="c13 c32 c10"><span class="c8"></span></p><p class="c4"><span class="c8">To minimize the loss as a function of the new image, the grad tool from the Theano library is used to get the gradient of the total loss as a function of the image input to the convolutional neural network. This is what produces a new image according to the losses calculated through VGG-19.</span></p><p class="c0 c10"><span></span></p><p class="c4"><span class="c2">4</span><span class="c2 c11">. Implementation </span></p><p class="c1"><span class="c8">This section describes the neural network used to extract features, how they were used to compute a loss function and how the loss function as used to produce new images.</span></p><p class="c4 c10"><span class="c3"></span></p><p class="c4"><span class="c2">4</span><span class="c2 c11">.1. Deep Learning </span><span class="c2">Network</span></p><p class="c4"><span class="c8">VGG-19 consists of the following of layers:</span></p><p class="c4"><span class="c12">- conv1_1 - conv1_2 - pool1</span></p><p class="c4"><span class="c12">- conv2_1 - conv2_2 - pool2</span></p><p class="c4"><span class="c12">- conv3_1 - conv3_2 - conv3_3 - conv3_4 - pool3</span></p><p class="c4"><span class="c12">- conv4_1 - conv4_2 - conv4_3 - conv4_4 - pool4</span></p><p class="c4"><span class="c12">- conv5_1 - conv5_2 - conv5_3 - conv5_4 - pool5</span></p><p class="c4"><span class="c12">- fc6 - drop6 - fc7 - drop7 - fc8 - prob</span></p><p class="c4"><span class="c8">Table 1: Layers in VGG-19</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">The following classes were implemented to create these layers, b</span><span class="c8">ased on the tutorials and homeworks in class, we created the following layer classes:</span></p><ol class="c34 lst-kix_6nqn63a3krj0-0 start" start="1"><li class="c4 c20"><span class="c8">LeNetConvLayer</span></li><li class="c4 c20"><span class="c8">HiddenLayer</span></li><li class="c4 c20"><span class="c8">LogisticRegressionLayer</span></li></ol><p class="c4"><span class="c8">The outputs were connected using standard pooling and dropout function provided by Theano library. The final computation graph and functions to train these are made available as a VGG_19 class to allow for modularity and re usage while experimenting in the following sections. Special care was taken to ensure that &nbsp;all the Models and Layers can be parameterized for different sizes of images, different activation functions. VGG_19 class can also take in weights that could be read from mat files and pass them to individual layers.</span></p><p class="c4"><span class="c8">The training algorithm consisted of using a Scipy function that did function minimization with L-BFGS, using two Python wrapped theano functions that calculate the loss and the grad with an initial guess of white noise. The data used for input were test images from the paper for content and style.</span></p><p class="c4 c10"><span class="c3"></span></p><p class="c4"><span class="c2">4</span><span class="c2 c11">.2. Software Design</span></p><p class="c4"><span class="c8">The following figure shows the process the data goes through to produce the new image</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 364.00px; height: 52.50px;"><img alt="FlowChart.png" src="images/image20.png" style="width: 364.00px; height: 52.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Neural network: Feedforward input through neural network and output activations at right layers</span></p><p class="c4"><span class="c8">Loss: Compute loss for every layer of style and content and output scalar loss</span></p><p class="c4"><span class="c8">Minimization: Using loss and gradient functions, minimize loss as a function on input, then send input back through CNN</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c2">5. Results</span></p><p class="c4"><span class="c2">5.1. Project Results</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; There are two principal categories of results produced by this project: the results of training VGG-19 and the style transfer results with the pretrained weights.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c7 c14">VGG-19 Training</span></p><p class="c4 c10"><span class="c7 c14"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 312.00px; height: 188.00px;"><img alt="figure_1.png" src="images/image07.png" style="width: 312.00px; height: 188.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c7 c14"></span></p><p class="c4"><span class="c8">Figure 3: VGG-19 Training Initialized with random weights</span></p><p class="c4"><span class="c8">The graph in figure 3 shows how the testing accuracy of VGG-19 initialized with random weights does not train appreciably after 100 epochs, with 31 mini-batches with 840 images in total across 10 categories . This justifies the use of the pretrained weights.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c7 c14">Style Transfer</span></p><p class="c4 c10"><span class="c7"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.55px; height: 119.50px;"><img alt="starry_night_google.jpg" src="images/image17.jpg" style="width: 150.55px; height: 119.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 152.73px; height: 115.50px;"><img alt="tubingen.jpg" src="images/image14.jpg" style="width: 152.73px; height: 115.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c7"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 296.83px; height: 224.63px;"><img alt="gen_0009.jpg" src="images/image05.jpg" style="width: 296.83px; height: 224.63px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 4: Generated Image with Tubingen content and The Starry Night (Van Gogh) style</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 4 clearly shows how style from the Van Gogh painting is applied to the photo of the Neckarfront - the outline of the building are clearly visible, as are their reflections in the water. The brush strokes are reminiscent of The Starry Night, as is the colour palette.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 168.92px; height: 127.50px;"><img alt="gen_0000.jpg" src="images/image08.jpg" style="width: 168.92px; height: 127.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 169.46px; height: 127.50px;"><img alt="gen_0004.jpg" src="images/image06.jpg" style="width: 169.46px; height: 127.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 169.53px; height: 129.50px;"><img alt="gen_0009.jpg" src="images/image11.jpg" style="width: 169.53px; height: 129.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 5: Progressive Style Transfer with LBGF-S : Top at iteration 0, middle at iteration 5, bottom at iteration 10</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">In figure 5, it can be observed that the generated image is in fact getting closer to the content of the content input and the style of the style input as the minimization of the loss occurs. Clear building shapes appear after 4 iterations, along with the brush strokes and colour palette of the style image. A more recognizable image is show after 5 more iterations.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.83px; height: 114.36px;"><img alt="gen_0009.jpg" src="images/image21.jpg" style="width: 150.83px; height: 114.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.83px; height: 114.12px;"><img alt="gen_0009.jpg" src="images/image13.jpg" style="width: 150.83px; height: 114.12px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 6: Comparison of Adam and L-BGFS after 10 iterations with Tubingen and The Shipwreck of the Minotaur by Turner</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 6 displays the superiority of minimization given by the L-BFGS minimization as compared to the Adam optimizer. The Adam optimizer does not provide an image similar to the one given by 10 iterations of L-BFGS until 50 more iterations. 10 iterations of Adam still produces an image similar to white noise. </span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 295.83px; height: 223.49px;"><img alt="gen_0009.jpg" src="images/image15.jpg" style="width: 295.83px; height: 223.49px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 7: Reconstructions at Content Layer conv4_2 of Tubingen</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 7 displays the reconstruction of the output of the conv4_2 layer of VGG-19 with the Neckarfront input image. The edges of the buildings and other objects are clearly displayed, but the colours are dulled, indicating that the output is especially content focused as opposed to style.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 307.83px; height: 232.27px;"><img alt="gen_0009.jpg" src="images/image10.jpg" style="width: 307.83px; height: 232.27px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 280.80px; height: 211.50px;"><img alt="gen_0009.jpg" src="images/image16.jpg" style="width: 280.80px; height: 211.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 8: Comparison of Alpha/Beta ratio - Top : alpha=0.2, beta = 1e-6, Bottom : &nbsp;alpha=0.2, beta = 1e-5</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 275.49px; height: 207.50px;"><img alt="gen_0009.jpg" src="images/image09.jpg" style="width: 275.49px; height: 207.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 9: Tubingen content with Femme Nue Assise by Picasso</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Figure 9 displays how profoundly the colour of the stye input affects the output. Here the content is hard to perceive because of the low contrast in the input style image.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 270.18px; height: 203.50px;"><img alt="gen_0009.jpg" src="images/image11.jpg" style="width: 270.18px; height: 203.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 10: Tubingen content with Composition VII by Kandinsky</span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 292.75px; height: 220.50px;"><img alt="content_style_loss.png" src="images/image12.png" style="width: 292.75px; height: 220.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 11 : Progression of loss when training for style loss and content loss with L-BFGS</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">Fig 11 shows how loss progresses during minimization. Style loss goes down much more quickly than content loss, which only goes down by a small amount.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c2">5.2. Comparison of Results </span></p><p class="c4"><span class="c8 c9">&nbsp; &nbsp; </span><span class="c8">&nbsp;These are the main images resulting from the style transfer in the paper.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 312.00px; height: 356.00px;"><img alt="tiff_paperres.png" src="images/image18.png" style="width: 312.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c4"><span class="c8">Figure 11: Results of the style transfer from the original paper</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c8">These images shown in the paper are much nicer than ones produced by the project. However, similar features can be observed. Both sets of results show transfer of colour and texture elements, such as brush strokes to the content image. The ones from the paper have a much greater level of detail of content, with smaller elements such as windows remaining clearly visible. The difference with the style from </span><span class="c14 c8">Femme nue assise</span><span class="c8">&nbsp;by Picasso is especially striking, as the image from the project lost almost all contrast. These differences can be attributed, to longer training times, better alpha and beta values, weight normalization and the use of average pooling.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4"><span class="c2">5.3. Discussion of Insights Gained </span></p><p class="c4"><span class="c8 c9">&nbsp; </span><span class="c8">This paper clearly displays the power of CNNs, especially deep CNNs, to mimic biological activity and extract important features from visual content. The different layers of CNNs show important features, similar to complex cells in the visual cortex, and these different features can be used for different all sorts of purposes and manipulation for image generation and classification.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp;It is also clear that not all applications of CNNs require high computation time - with good optimization, this new content can be generated in minutes.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp;Finally, this CNN also shows the power of Theano, especially by its ability to compute the grad of complex computational graphs, allowing loss minimization in an elegant manner.</span></p><p class="c4"><span class="c8">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c2 c11">&nbsp;</span><span class="c2">6</span><span class="c2 c11">. Conclusion </span></p><p class="c4 c35"><span class="c8">In conclusion, this project shows the ability of CNNs to separate style and content from visual representations. Powerful feature extractors allow to identify style elements and content elements and novel loss functions help combine the 2 to create new content sourced from the two. While working around hardware limitations many optimizations in the architecture were made to obtain quick results of combining the style and content. An interesting modification for this paper would be to create a loss function for 3 images separated into foreground and background, where we take the style of one background of image 1, style of foreground of image 2 and apply it to the respective components of image 3.</span></p><p class="c4 c10"><span class="c5 c16"></span></p><p class="c4"><span class="c2 c11">6. Acknowledgement</span></p><p class="c13"><span class="c8">Thank you to Mehmet Turkcan and James Lloyd for actively explaining some sticky points in the paper.</span></p><p class="c13"><span class="c8">Thank you to fchollet (https://github.com/fchollet/keras/blob/master/examples/neural_style_transfer.py) for the Keras implementation and jcjohnson (https://github.com/jcjohnson/neural-style) for the Torch implementation and webeng for L-BFGS with Theano example (https://github.com/Lasagne/Recipes/blob/master/examples/styletransfer/Art%20Style%20Transfer.ipynb) available on Github</span></p><p class="c4"><span class="c2 c11">7. References</span></p><p class="c4"><span class="c8 c9">[1] https://bitbucket.org/e_4040_ta/e4040_project_naah</span></p><p class="c4"><span class="c5">[</span><span class="c8">2</span><span class="c5">] Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems,1097&ndash;1105(2012).URL </span><span class="c5 c27"><a class="c25" href="https://www.google.com/url?q=http://papers.nips.cc/paper/4824-imagenet&amp;sa=D&amp;ust=1483741098229000&amp;usg=AFQjCNH2kwXv7lI_RFHWtFAc26Cf3COayA">http://papers.nips.cc/paper/4824-imagenet</a></span><span class="c5">.</span></p><p class="c4"><span class="c8">[3] Taigman, Y., Yang, M., Ranzato, M. &amp; Wolf, L. Deepface: Closing the gap to human-level performance in face verification. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, 1701&ndash;1708 (IEEE, 2014). URL http://ieeexplore. ieee.org/xpls/abs_all.jsp?arnumber=6909616</span></p><p class="c4"><span class="c8">[4]Simonyan, Karen, and Andrew Zisserman. &quot;Very deep convolutional networks for large-scale image recognition.&quot; </span><span class="c14 c8">arXiv preprint arXiv:1409.1556</span><span class="c8">&nbsp;(2014).</span></p><p class="c4"><span class="c8">[5] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. &quot;A neural algorithm of artistic style.&quot; </span><span class="c14 c8">arXiv preprint arXiv:1508.06576</span><span class="c8">&nbsp;(2015).</span></p><p class="c4"><span class="c8">[6] Lloyd, James Robert, &ldquo;Neural Art&rdquo;, </span><span class="c27 c8"><a class="c25" href="https://www.google.com/url?q=http://jamesrobertlloyd.com/blog-2015-09-01-neural-art.html&amp;sa=D&amp;ust=1483741098233000&amp;usg=AFQjCNFoaGQS7qqQujRf-TsZAqu2Z8fA5Q">http://jamesrobertlloyd.com/blog-2015-09-01-neural-art.html</a></span><span class="c8">. Consulted on December 18th 2016</span></p><p class="c4"><span class="c8">[7] Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. &quot;Image style transfer using convolutional neural networks.&quot; </span><span class="c14 c8">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</span><span class="c8">. 2016.</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c5 c16"></span></p><p class="c4 c10"><span class="c2"></span></p><p class="c4"><span class="c2 c11">8. Appendix</span></p><p class="c4"><span class="c8">&nbsp;</span></p><p class="c4"><span class="c2 c8">8.1 Individual student contributions - table</span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c8"></span></p><a id="t.76e0292966e97ea225c050836e50b3fe0ce37698"></a><a id="t.0"></a><table class="c29"><tbody><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6 c10"><span class="c19 c5 c16"></span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">fam2148</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">yg2482</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c0 c26"><span>rg3047</span></p></td></tr><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Last Name</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Marcogliese</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Garg</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Godden</span></p></td></tr><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Fraction of (useful) total contribution</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">1/3</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">1/3</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">1/3</span></p></td></tr><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">What I did 1</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">wrote report</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">wrote report</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c6"><span class="c5 c16 c19">VGG-19 perfection</span></p></td></tr><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">What I did 2</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">LBFG-S implementation</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">VGG training</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">Loss functions</span></p></td></tr><tr class="c23"><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">What I did 3</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">finalized code to style transfer</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">initial NN setup</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c6"><span class="c19 c5 c16">alpha beta optimization</span></p></td></tr></tbody></table><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c8"></span></p><p class="c4 c10"><span class="c3"></span></p></body></html>